version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dharma-backend
    ports:
      - "8080:8080"
    environment:
      # Required: Set your Gemini API key
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      # Optional: Investigation-specific Gemini API key (falls back to GEMINI_API_KEY if not set)
      - GEMINI_API_KEY_INVESTIGATION=${GEMINI_API_KEY_INVESTIGATION:-}
      # Optional: Legal suggestions Gemini API key (falls back to GEMINI_API_KEY if not set)
      - GEMINI_API_KEY_LEGAL_SUGGESTIONS=${GEMINI_API_KEY_LEGAL_SUGGESTIONS:-}
      # Optional: Sketch generation Gemini API key (falls back to GEMINI_API_KEY_INVESTIGATION if not set)
      - GEMINI_API_KEY_SKETCH=${GEMINI_API_KEY_SKETCH:-}
      # Optional: Hugging Face token for complaint processing
      - HF_TOKEN=${HF_TOKEN:-}
      # Optional: Custom reports directory
      - INVESTIGATION_REPORTS_DIR=${INVESTIGATION_REPORTS_DIR:-generated_reports}
      # Legal RAG Configuration (optional - set to enable RAG)
      - LEGAL_RAG_ENABLED=${LEGAL_RAG_ENABLED:-false}
      - LEGAL_RAG_DB_PATH=${LEGAL_RAG_DB_PATH:-/app/legal_rag/chroma_db}
      - LEGAL_RAG_COLLECTION=${LEGAL_RAG_COLLECTION:-langchain}
      - LEGAL_RAG_EMBEDDING_MODEL=${LEGAL_RAG_EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      # Set PORT to match Dockerfile
      - PORT=8080
    volumes:
      # Mount reports directory to persist generated PDFs
      - ./generated_reports:/app/generated_reports
      # Mount temp_videos directory for ANPR video processing
      - ./temp_videos:/app/temp_videos
      # Mount models directory to persist ML models
      - ./models:/app/models
      # Mount legal_rag directory to persist ChromaDB vector database
      - ./legal_rag:/app/legal_rag
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

